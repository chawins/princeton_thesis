{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify visible cuda device\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chawins/.conda/envs/tsa3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/chawins/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "from parameters import *\n",
    "from lib.utils import *\n",
    "from lib.attacks import *\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "x_train, y_train, x_test, y_test = load_dataset_mnist()\n",
    "\n",
    "y_train_cat = keras.utils.to_categorical(y_train, NUM_LABELS)\n",
    "y_test_cat = keras.utils.to_categorical(y_test, NUM_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_mnist_A_hinge(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[3, 3],\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Convolutional Layer and pooling #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=conv1,\n",
    "        filters=64,\n",
    "        kernel_size=[3, 3],\n",
    "        activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dropout #1\n",
    "    drop1 = tf.layers.dropout(\n",
    "        inputs=pool1, rate=0.25, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    \n",
    "    # Dense Layer\n",
    "    drop1_flat = tf.reshape(drop1, [-1, 12 * 12 * 64])\n",
    "    dense = tf.layers.dense(inputs=drop1_flat, units=128, activation=tf.nn.relu)\n",
    "    drop2 = tf.layers.dropout(\n",
    "        inputs=dense, rate=0.5, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=drop2, units=10, name=\"logits\")\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    " \n",
    "    # Structured hinge loss max{0, 1 - (y_label - y_max)}\n",
    "    # Not so elegant way to index tensor with another tensor\n",
    "    indices = tf.range(tf.shape(logits)[0])\n",
    "    gather_ind = tf.stack([indices, labels], axis=1)\n",
    "    y_label = tf.gather_nd(logits, gather_ind)\n",
    "    # Get 2 largest outputs\n",
    "    y_2max = tf.nn.top_k(logits, 2)[0]\n",
    "    # Find y_max = max(z[i != y])\n",
    "    i_max = tf.to_int32(tf.argmax(logits, axis=1))\n",
    "    y_max = tf.where(tf.equal(labels, i_max), y_2max[:, 1],\n",
    "                     y_2max[:, 0])\n",
    "    loss = tf.reduce_sum(tf.maximum(0., 100. - y_label + y_max))\n",
    "    \n",
    "    # Calculate batch accuracy\n",
    "    tmp = tf.cast(tf.equal(i_max, labels), dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tmp, name=\"accuracy\")\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_mnist_B_hinge(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=128,\n",
    "        kernel_size=[3, 3],\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Convolutional Layer and pooling #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=conv1,\n",
    "        filters=256,\n",
    "        kernel_size=[3, 3],\n",
    "        activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dropout #1\n",
    "    drop1 = tf.layers.dropout(\n",
    "        inputs=pool1, rate=0.25, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    \n",
    "    # Dense Layer\n",
    "    drop1_flat = tf.reshape(drop1, [-1, 12 * 12 * 256])\n",
    "    dense = tf.layers.dense(inputs=drop1_flat, units=512, activation=tf.nn.relu)\n",
    "    drop2 = tf.layers.dropout(\n",
    "        inputs=dense, rate=0.5, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=drop2, units=10, name=\"logits\")\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    " \n",
    "    # Structured hinge loss max{0, 1 - (y_label - y_max)}\n",
    "    # Not so elegant way to index tensor with another tensor\n",
    "    indices = tf.range(tf.shape(logits)[0])\n",
    "    gather_ind = tf.stack([indices, labels], axis=1)\n",
    "    y_label = tf.gather_nd(logits, gather_ind)\n",
    "    # Get 2 largest outputs\n",
    "    y_2max = tf.nn.top_k(logits, 2)[0]\n",
    "    # Find y_max = max(z[i != y])\n",
    "    i_max = tf.to_int32(tf.argmax(logits, axis=1))\n",
    "    y_max = tf.where(tf.equal(labels, i_max), y_2max[:, 1],\n",
    "                     y_2max[:, 0])\n",
    "    loss = tf.reduce_sum(tf.maximum(0., 10000. - y_label + y_max))\n",
    "    \n",
    "    # Calculate batch accuracy\n",
    "    tmp = tf.cast(tf.equal(i_max, labels), dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tmp, name=\"accuracy\")\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_mnist_C_hinge(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 784])\n",
    "\n",
    "    dense = tf.layers.dense(inputs=input_layer, units=300, activation=tf.nn.relu)\n",
    "    drop = tf.layers.dropout(\n",
    "        inputs=dense, rate=0.25, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    for _ in range(3):\n",
    "        dense = tf.layers.dense(inputs=drop, units=300, activation=tf.nn.relu)\n",
    "        drop = tf.layers.dropout(\n",
    "            inputs=dense, rate=0.25, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    \n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=drop, units=10, name=\"logits\")\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    " \n",
    "    # Structured hinge loss max{0, 1 - (y_label - y_max)}\n",
    "    # Not so elegant way to index tensor with another tensor\n",
    "    indices = tf.range(tf.shape(logits)[0])\n",
    "    gather_ind = tf.stack([indices, labels], axis=1)\n",
    "    y_label = tf.gather_nd(logits, gather_ind)\n",
    "    # Get 2 largest outputs\n",
    "    y_2max = tf.nn.top_k(logits, 2)[0]\n",
    "    # Find y_max = max(z[i != y])\n",
    "    i_max = tf.to_int32(tf.argmax(logits, axis=1))\n",
    "    y_max = tf.where(tf.equal(labels, i_max), y_2max[:, 1],\n",
    "                     y_2max[:, 0])\n",
    "    loss = tf.reduce_sum(tf.maximum(0., 1e2 - y_label + y_max))\n",
    "    \n",
    "    # Calculate batch accuracy\n",
    "    tmp = tf.cast(tf.equal(i_max, labels), dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tmp, name=\"accuracy\")\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_mnist_D_hinge(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 784])\n",
    "\n",
    "    dense = tf.layers.dense(inputs=input_layer, units=1200, activation=tf.nn.relu)\n",
    "    drop = tf.layers.dropout(\n",
    "        inputs=dense, rate=0., training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    for _ in range(5):\n",
    "        dense = tf.layers.dense(inputs=drop, units=1200, activation=tf.nn.relu)\n",
    "        drop = tf.layers.dropout(\n",
    "            inputs=dense, rate=0., training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    \n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=drop, units=10, name=\"logits\")\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    " \n",
    "    # Structured hinge loss max{0, 1 - (y_label - y_max)}\n",
    "    # Not so elegant way to index tensor with another tensor\n",
    "    indices = tf.range(tf.shape(logits)[0])\n",
    "    gather_ind = tf.stack([indices, labels], axis=1)\n",
    "    y_label = tf.gather_nd(logits, gather_ind)\n",
    "    # Get 2 largest outputs\n",
    "    y_2max = tf.nn.top_k(logits, 2)[0]\n",
    "    # Find y_max = max(z[i != y])\n",
    "    i_max = tf.to_int32(tf.argmax(logits, axis=1))\n",
    "    y_max = tf.where(tf.equal(labels, i_max), y_2max[:, 1],\n",
    "                     y_2max[:, 0])\n",
    "    loss = tf.reduce_sum(tf.maximum(0., 1e4 - y_label + y_max))\n",
    "    \n",
    "    # Calculate batch accuracy\n",
    "    tmp = tf.cast(tf.equal(i_max, labels), dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tmp, name=\"accuracy\")\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_mnist_A_margin(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    \n",
    "    C = 1e2\n",
    "    lamda = 1e-2\n",
    "    EPS = 1e-6\n",
    "    \n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[3, 3],\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Convolutional Layer and pooling #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=conv1,\n",
    "        filters=64,\n",
    "        kernel_size=[3, 3],\n",
    "        activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dropout #1\n",
    "    drop1 = tf.layers.dropout(\n",
    "        inputs=pool1, rate=0., training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    \n",
    "    # Dense Layer\n",
    "    drop1_flat = tf.reshape(drop1, [-1, 12 * 12 * 64])\n",
    "    dense = tf.layers.dense(inputs=drop1_flat, units=128, activation=tf.nn.relu)\n",
    "    drop2 = tf.layers.dropout(\n",
    "        inputs=dense, rate=0., training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=drop2, units=10, name=\"logits\")\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    " \n",
    "    # Structured hinge loss max{0, 1 - (y_label - y_max)}\n",
    "    # Not so elegant way to index tensor with another tensor\n",
    "    indices = tf.range(tf.shape(logits)[0])\n",
    "    gather_ind = tf.stack([indices, labels], axis=1)\n",
    "    y_label = tf.gather_nd(logits, gather_ind)\n",
    "    # Get 2 largest outputs\n",
    "    y_2max = tf.nn.top_k(logits, 2)[0]\n",
    "    # Find y_max = max(z[i != y])\n",
    "    i_max = tf.to_int32(tf.argmax(logits, axis=1))\n",
    "    y_max = tf.where(tf.equal(labels, i_max), y_2max[:, 1],\n",
    "                     y_2max[:, 0])\n",
    "    loss = tf.reduce_sum(tf.maximum(0., C - y_label + y_max))\n",
    "    \n",
    "    # Add penalty term\n",
    "    grad = tf.gradients(y_label, input_layer, name='grad')\n",
    "    grad_reshape = tf.reshape(grad, shape=[-1, 28 * 28])\n",
    "    # grad_norm = tf.reduce_sum(tf.square(grad_reshape), axis=1)\n",
    "    grad_norm = tf.sqrt(tf.reduce_sum(tf.square(grad_reshape), axis=1))\n",
    "    # diff = tf.square(y_label - y_max)\n",
    "    diff = tf.abs(y_label - y_max)\n",
    "    # diff = y_label\n",
    "    margin = tf.divide(grad_norm, diff + EPS)\n",
    "    penalty = tf.reduce_sum(margin, name='penalty')\n",
    "    loss += lamda * penalty\n",
    "    \n",
    "    # Calculate batch accuracy\n",
    "    tmp = tf.cast(tf.equal(i_max, labels), dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tmp, name=\"accuracy\")\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_mnist_B_margin(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    \n",
    "    C = 1\n",
    "    lamda = 1e-7\n",
    "    EPS = 1e-6\n",
    "    \n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=128,\n",
    "        kernel_size=[3, 3],\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Convolutional Layer and pooling #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=conv1,\n",
    "        filters=256,\n",
    "        kernel_size=[3, 3],\n",
    "        activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dropout #1\n",
    "    drop1 = tf.layers.dropout(\n",
    "        inputs=pool1, rate=0.25, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    \n",
    "    # Dense Layer\n",
    "    drop1_flat = tf.reshape(drop1, [-1, 12 * 12 * 256])\n",
    "    dense = tf.layers.dense(inputs=drop1_flat, units=512, activation=tf.nn.relu)\n",
    "    drop2 = tf.layers.dropout(\n",
    "        inputs=dense, rate=0.5, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=drop2, units=10, name=\"logits\")\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    " \n",
    "    # Structured hinge loss max{0, 1 - (y_label - y_max)}\n",
    "    # Not so elegant way to index tensor with another tensor\n",
    "    indices = tf.range(tf.shape(logits)[0])\n",
    "    gather_ind = tf.stack([indices, labels], axis=1)\n",
    "    y_label = tf.gather_nd(logits, gather_ind)\n",
    "    # Get 2 largest outputs\n",
    "    y_2max = tf.nn.top_k(logits, 2)[0]\n",
    "    # Find y_max = max(z[i != y])\n",
    "    i_max = tf.to_int32(tf.argmax(logits, axis=1))\n",
    "    y_max = tf.where(tf.equal(labels, i_max), y_2max[:, 1],\n",
    "                     y_2max[:, 0])\n",
    "    loss = tf.reduce_sum(tf.maximum(0., C - y_label + y_max))\n",
    "    \n",
    "    # Add penalty term\n",
    "    grad = tf.gradients(y_label, input_layer, name='grad')\n",
    "    grad_reshape = tf.reshape(grad, shape=[-1, 28 * 28])\n",
    "    grad_norm = tf.reduce_sum(tf.square(grad_reshape), axis=1)\n",
    "    diff = tf.square(y_label - y_max)\n",
    "    margin = tf.divide(grad_norm, diff)\n",
    "    # margin = tf.divide(grad_norm, (y_label + EPS))\n",
    "    penalty = tf.reduce_sum(margin, name='penalty')\n",
    "    loss += lamda * penalty\n",
    "    \n",
    "    # Calculate batch accuracy\n",
    "    tmp = tf.cast(tf.equal(i_max, labels), dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tmp, name=\"accuracy\")\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './tmp/mnist_0_margin_c1e2_l1e-2/'\n",
    "model_fn = fn_mnist_A_margin\n",
    "# path = './tmp/mnist_a_margin_c1e4/'\n",
    "# model_fn = fn_mnist_A_hinge\n",
    "model = build_cnn_mnist()\n",
    "# model = build_cnn_mnist_2()\n",
    "# model = build_dnn_mnist(784, 300, 4)\n",
    "# model = build_dnn_mnist(784, 1200, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './tmp/mnist_0_margin_c1e2_l1e-2/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa67585be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=model_fn, model_dir=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "#tensors_to_log = {\"gather_ind\": \"gather_ind\", \"y_l\": \"y_l\"}\n",
    "tensors_to_log = {\"accuracy\": \"accuracy\", \"penalty\": \"penalty\"}\n",
    "#tensors_to_log = {\"accuracy\": \"accuracy\"}\n",
    "#tensors_to_log = {}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(estimator):\n",
    "    \"\"\"\n",
    "    Extract weights from TF Estimator. Only works with a simple CNN/DNN.\n",
    "    \"\"\"\n",
    "\n",
    "    weights = []\n",
    "    weight = []\n",
    "    layer_names = estimator.get_variable_names()\n",
    "    for layer_name in layer_names:\n",
    "        if layer_name.endswith(\"kernel\"):\n",
    "            weight.insert(0, estimator.get_variable_value(layer_name))\n",
    "            weights.append(weight)\n",
    "            weight = []\n",
    "        elif layer_name.endswith(\"bias\"):\n",
    "            weight.append(estimator.get_variable_value(layer_name))\n",
    "            \n",
    "    return weights\n",
    "\n",
    "\n",
    "def load_weights(model, weights):\n",
    "    \"\"\"\n",
    "    Set weights in Keras model with a list of weights.\n",
    "    \"\"\"\n",
    "    \n",
    "    i = 0\n",
    "    for layer in model.layers:\n",
    "        # Check if layer has trainable weights\n",
    "        if not layer.trainable_weights:\n",
    "            continue\n",
    "        # Set weight\n",
    "        layer.set_weights(weights[i])\n",
    "        i += 1\n",
    "        \n",
    "    assert i == len(weights), \"Number of layers mismatch.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./tmp/mnist_0_margin_c1e2_l1e-2/model.ckpt.\n",
      "INFO:tensorflow:accuracy = 0.0703125, penalty = 317.42233\n",
      "INFO:tensorflow:loss = 12814.0625, step = 0\n",
      "INFO:tensorflow:global_step/sec: 88.3602\n",
      "INFO:tensorflow:accuracy = 0.0625, penalty = 29.615326 (1.139 sec)\n",
      "INFO:tensorflow:loss = 12974.3125, step = 100 (1.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.228\n",
      "INFO:tensorflow:accuracy = 0.140625, penalty = 24.690353 (0.955 sec)\n",
      "INFO:tensorflow:loss = 13024.487, step = 200 (0.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.125\n",
      "INFO:tensorflow:accuracy = 0.2109375, penalty = 119.797195 (0.934 sec)\n",
      "INFO:tensorflow:loss = 12874.214, step = 300 (0.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.044\n",
      "INFO:tensorflow:accuracy = 0.140625, penalty = 21.325344 (0.943 sec)\n",
      "INFO:tensorflow:loss = 13092.829, step = 400 (0.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.855\n",
      "INFO:tensorflow:accuracy = 0.09375, penalty = 18.569408 (0.964 sec)\n",
      "INFO:tensorflow:loss = 13232.582, step = 500 (0.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.689\n",
      "INFO:tensorflow:accuracy = 0.078125, penalty = 10.806121 (0.945 sec)\n",
      "INFO:tensorflow:loss = 13951.776, step = 600 (0.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.846\n",
      "INFO:tensorflow:accuracy = 0.1328125, penalty = 19.741444 (0.936 sec)\n",
      "INFO:tensorflow:loss = 13596.466, step = 700 (0.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.708\n",
      "INFO:tensorflow:accuracy = 0.109375, penalty = 28.248093 (0.937 sec)\n",
      "INFO:tensorflow:loss = 12999.659, step = 800 (0.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.526\n",
      "INFO:tensorflow:accuracy = 0.09375, penalty = 180.14928 (0.948 sec)\n",
      "INFO:tensorflow:loss = 13035.422, step = 900 (0.948 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 938 into ./tmp/mnist_0_margin_c1e2_l1e-2/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6525.5615.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-04-13:48:13\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/mnist_0_margin_c1e2_l1e-2/model.ckpt-938\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-04-13:48:15\n",
      "INFO:tensorflow:Saving dict for global step 938: accuracy = 0.09736667, global_step = 938, loss = 13101.16\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-04-13:48:15\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/mnist_0_margin_c1e2_l1e-2/model.ckpt-938\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-04-13:48:16\n",
      "INFO:tensorflow:Saving dict for global step 938: accuracy = 0.0982, global_step = 938, loss = 12964.78\n",
      "=========== (-) Test loss: 12964.78027 =============\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/mnist_0_margin_c1e2_l1e-2/model.ckpt-938\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 939 into ./tmp/mnist_0_margin_c1e2_l1e-2/model.ckpt.\n",
      "INFO:tensorflow:accuracy = 0.109375, penalty = 22.777422\n",
      "INFO:tensorflow:loss = 13125.381, step = 938\n",
      "INFO:tensorflow:global_step/sec: 85.6584\n",
      "INFO:tensorflow:accuracy = 0.1015625, penalty = 135.45456 (1.170 sec)\n",
      "INFO:tensorflow:loss = 12992.664, step = 1038 (1.169 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3bf72e75ebdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             mnist_classifier.train(\n\u001b[1;32m     22\u001b[0m                 \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 hooks=[logging_hook])\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    544\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1023\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weight_path = path + 'model'\n",
    "n_epochs = 200\n",
    "stop_counter = 0\n",
    "\n",
    "min_test_loss = np.inf\n",
    "save_i = 0\n",
    "train_out = {'accuracy': [], 'loss':[]}\n",
    "test_out = {'accuracy': [], 'loss':[]}\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    \n",
    "    if i % 2 is 0:\n",
    "        try:\n",
    "            train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "                x={\"x\": x_train},\n",
    "                y=y_train,\n",
    "                batch_size=128,\n",
    "                num_epochs=2,\n",
    "                shuffle=True)       \n",
    "\n",
    "            mnist_classifier.train(\n",
    "                input_fn=train_input_fn,\n",
    "                hooks=[logging_hook])\n",
    "\n",
    "            eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "                x={\"x\": x_train},\n",
    "                y=y_train,\n",
    "                num_epochs=1,\n",
    "                shuffle=False)\n",
    "            eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "            train_out['accuracy'].append(eval_results['accuracy'])\n",
    "            train_out['loss'].append(eval_results['loss'])\n",
    "\n",
    "            eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "                x={\"x\": x_test},\n",
    "                y=y_test,\n",
    "                num_epochs=1,\n",
    "                shuffle=False)\n",
    "            eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "            test_loss = eval_results['loss']\n",
    "            test_out['accuracy'].append(test_loss)\n",
    "            test_out['loss'].append(eval_results['loss'])\n",
    "\n",
    "            if test_loss < min_test_loss:\n",
    "                min_test_loss = test_loss\n",
    "                save_i = i\n",
    "                weights = get_weights(mnist_classifier)\n",
    "                load_weights(model, weights)\n",
    "                model.save_weights(weight_path + '.h5')\n",
    "                stop_counter = 0\n",
    "                print('=========== (-) Test loss: {:.5f} ============='.format(test_loss))\n",
    "            else:\n",
    "                stop_counter += 1\n",
    "                print('=========== (+) Test loss: {:.5f} ============='.format(test_loss))\n",
    "\n",
    "            if stop_counter == 5:\n",
    "                break\n",
    "                \n",
    "        except:\n",
    "            raise\n",
    "            print('--------- NaN encountered - epoch {} ---------'.format(i))\n",
    "            pass\n",
    "\n",
    "print('================ Finished in {} epochs ================'.format(i))\n",
    "pickle.dump(train_out, open(weight_path + '_train.p', 'wb'))\n",
    "pickle.dump(test_out, open(weight_path + '_test.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#     x={\"x\": x_train},\n",
    "#     y=y_train,\n",
    "#     batch_size=128,\n",
    "#     num_epochs=5,\n",
    "#     shuffle=True)\n",
    "\n",
    "# mnist_classifier.train(\n",
    "#     input_fn=train_input_fn,\n",
    "#     hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_cnn_mnist()\n",
    "#model = build_cnn_mnist_2()\n",
    "#model = build_dnn_mnist(784, 300, 4)\n",
    "#model = build_dnn_mnist(784, 1200, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(path + 'model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 83us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0007422032472302, 0.9887]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 69us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.302701156801376, 0.9965666666666667]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train, y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we change margin? it doesn't have to be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_cnn_mnist()\n",
    "#model.load_weights('./tmp/weights/mnist_cnn_hinge.h5')\n",
    "#model.load_weights('./tmp/weights/mnist_cnn_smxe.h5')\n",
    "model.load_weights('./tmp/mnist_cnn_margin_C1_L1/model.h5')\n",
    "\n",
    "weight_path = './tmp/mnist_cnn_margin_C1_L1/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.OptCarlini import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, norm=7.587, loss=1.774, obj=9.361\n",
      "Step: 50, norm=6.586, loss=0.387, obj=6.973\n",
      "Step: 100, norm=5.647, loss=0.028, obj=5.675\n",
      "Step: 150, norm=4.993, loss=0.012, obj=5.005\n",
      "Step: 200, norm=4.715, loss=0.000, obj=4.715\n",
      "Step: 250, norm=4.574, loss=0.027, obj=4.601\n",
      "Step: 300, norm=4.496, loss=0.000, obj=4.496\n",
      "Step: 350, norm=4.448, loss=0.000, obj=4.448\n",
      "Step: 400, norm=4.403, loss=0.019, obj=4.423\n",
      "Step: 450, norm=4.396, loss=0.000, obj=4.396\n",
      "Step: 500, norm=4.375, loss=0.012, obj=4.387\n",
      "Step: 550, norm=4.369, loss=0.002, obj=4.371\n",
      "Step: 600, norm=4.359, loss=0.004, obj=4.362\n",
      "Step: 650, norm=4.351, loss=0.001, obj=4.352\n",
      "Step: 700, norm=4.346, loss=0.000, obj=4.346\n",
      "Step: 750, norm=4.337, loss=0.002, obj=4.340\n",
      "Step: 800, norm=4.341, loss=0.000, obj=4.341\n",
      "Step: 850, norm=4.329, loss=0.003, obj=4.332\n",
      "Step: 900, norm=4.323, loss=0.010, obj=4.333\n",
      "Step: 950, norm=4.328, loss=0.000, obj=4.328\n",
      "Step: 0, norm=7.823, loss=1.231, obj=9.054\n",
      "Step: 50, norm=6.108, loss=0.000, obj=6.108\n",
      "Step: 100, norm=4.666, loss=0.000, obj=4.666\n",
      "Step: 150, norm=3.790, loss=0.010, obj=3.801\n",
      "Step: 200, norm=3.384, loss=0.000, obj=3.384\n",
      "Step: 250, norm=3.215, loss=0.005, obj=3.220\n",
      "Step: 300, norm=3.128, loss=0.002, obj=3.130\n",
      "Step: 350, norm=3.074, loss=0.003, obj=3.077\n",
      "Step: 400, norm=3.039, loss=0.004, obj=3.043\n",
      "Step: 450, norm=3.015, loss=0.005, obj=3.020\n",
      "Step: 500, norm=2.993, loss=0.009, obj=3.002\n",
      "Step: 550, norm=2.977, loss=0.011, obj=2.988\n",
      "Step: 600, norm=2.970, loss=0.005, obj=2.976\n",
      "Step: 650, norm=2.966, loss=0.000, obj=2.966\n",
      "Step: 700, norm=2.953, loss=0.009, obj=2.961\n",
      "Step: 750, norm=2.954, loss=0.000, obj=2.954\n",
      "Step: 800, norm=2.949, loss=0.001, obj=2.950\n",
      "Step: 850, norm=2.941, loss=0.006, obj=2.946\n",
      "Step: 900, norm=2.942, loss=0.000, obj=2.942\n",
      "Step: 950, norm=2.933, loss=0.007, obj=2.940\n",
      "Step: 0, norm=7.629, loss=1.174, obj=8.804\n",
      "Step: 50, norm=6.310, loss=0.012, obj=6.321\n",
      "Step: 100, norm=5.152, loss=0.004, obj=5.156\n",
      "Step: 150, norm=4.578, loss=0.001, obj=4.579\n",
      "Step: 200, norm=4.247, loss=0.022, obj=4.269\n",
      "Step: 250, norm=4.055, loss=0.004, obj=4.059\n",
      "Step: 300, norm=3.807, loss=0.000, obj=3.807\n",
      "Step: 350, norm=3.713, loss=0.021, obj=3.734\n",
      "Step: 400, norm=3.692, loss=0.000, obj=3.692\n",
      "Step: 450, norm=3.656, loss=0.005, obj=3.660\n",
      "Step: 500, norm=3.642, loss=0.000, obj=3.642\n",
      "Step: 550, norm=3.625, loss=0.005, obj=3.631\n",
      "Step: 600, norm=3.613, loss=0.007, obj=3.620\n",
      "Step: 650, norm=3.611, loss=0.000, obj=3.611\n",
      "Step: 700, norm=3.603, loss=0.000, obj=3.603\n",
      "Step: 750, norm=3.594, loss=0.004, obj=3.598\n",
      "Step: 800, norm=3.589, loss=0.003, obj=3.592\n",
      "Step: 850, norm=3.586, loss=0.000, obj=3.586\n",
      "Step: 900, norm=3.581, loss=0.000, obj=3.581\n",
      "Step: 950, norm=3.576, loss=0.000, obj=3.576\n",
      "Step: 0, norm=7.900, loss=0.632, obj=8.532\n",
      "Step: 50, norm=6.196, loss=0.015, obj=6.211\n",
      "Step: 100, norm=4.923, loss=0.000, obj=4.923\n",
      "Step: 150, norm=4.270, loss=0.000, obj=4.270\n",
      "Step: 200, norm=4.023, loss=0.001, obj=4.024\n",
      "Step: 250, norm=3.926, loss=0.002, obj=3.929\n",
      "Step: 300, norm=3.872, loss=0.009, obj=3.881\n",
      "Step: 350, norm=3.846, loss=0.005, obj=3.851\n",
      "Step: 400, norm=3.820, loss=0.011, obj=3.831\n",
      "Step: 450, norm=3.817, loss=0.000, obj=3.817\n",
      "Step: 500, norm=3.797, loss=0.010, obj=3.808\n",
      "Step: 550, norm=3.793, loss=0.006, obj=3.799\n",
      "Step: 600, norm=3.789, loss=0.003, obj=3.792\n",
      "Step: 650, norm=3.777, loss=0.011, obj=3.788\n",
      "Step: 700, norm=3.780, loss=0.003, obj=3.783\n",
      "Step: 750, norm=3.777, loss=0.002, obj=3.779\n",
      "Step: 800, norm=3.769, loss=0.008, obj=3.777\n",
      "Step: 850, norm=3.774, loss=0.000, obj=3.774\n",
      "Step: 900, norm=3.762, loss=0.012, obj=3.774\n",
      "Step: 950, norm=3.768, loss=0.002, obj=3.770\n",
      "Step: 0, norm=7.783, loss=0.881, obj=8.664\n",
      "Step: 50, norm=6.233, loss=0.000, obj=6.233\n",
      "Step: 100, norm=5.035, loss=0.011, obj=5.046\n",
      "Step: 150, norm=4.385, loss=0.000, obj=4.385\n",
      "Step: 200, norm=4.089, loss=0.006, obj=4.095\n",
      "Step: 250, norm=3.965, loss=0.000, obj=3.965\n",
      "Step: 300, norm=3.893, loss=0.000, obj=3.893\n",
      "Step: 350, norm=3.846, loss=0.000, obj=3.846\n",
      "Step: 400, norm=3.809, loss=0.000, obj=3.809\n",
      "Step: 450, norm=3.790, loss=0.000, obj=3.790\n",
      "Step: 500, norm=3.771, loss=0.000, obj=3.771\n",
      "Step: 550, norm=3.765, loss=0.000, obj=3.765\n",
      "Step: 600, norm=3.757, loss=0.000, obj=3.757\n",
      "Step: 650, norm=3.739, loss=0.006, obj=3.744\n",
      "Step: 700, norm=3.734, loss=0.001, obj=3.735\n",
      "Step: 750, norm=3.729, loss=0.000, obj=3.729\n",
      "Step: 800, norm=3.724, loss=0.001, obj=3.725\n",
      "Step: 850, norm=3.722, loss=0.000, obj=3.722\n",
      "Step: 900, norm=3.716, loss=0.000, obj=3.716\n",
      "Step: 950, norm=3.712, loss=0.002, obj=3.714\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-4685b9bbfccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         x_adv[i], norm[i] = opt.optimize(x, y, \n\u001b[1;32m     12\u001b[0m                                          \u001b[0mweight_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                          n_step=1000, prog=True)\n\u001b[0m",
      "\u001b[0;32m~/princeton_thesis/lib/OptCarlini.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, x, y, weights_path, n_step, prog, mask)\u001b[0m\n\u001b[1;32m    226\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# Keep track of \"best\" solution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = OptCarlini(model, target=False, c=1, lr=0.01, init_scl=0.4,\n",
    "                 use_bound=False, loss_op=0, k=0, var_change=True,\n",
    "                 use_mask=False)\n",
    "\n",
    "x_adv = np.zeros_like(x_test)\n",
    "norm = np.zeros(len(x_test))\n",
    "\n",
    "for i, (x, y) in enumerate(zip(x_test, y_test_cat)):\n",
    "    y_pred = predict(model, x)\n",
    "    if y_pred is not np.argmax(y):\n",
    "        x_adv[i], norm[i] = opt.optimize(x, y, \n",
    "                                         weight_path + '.h5', \n",
    "                                         n_step=1000, prog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, norm=13.470, loss=0.000, obj=13.470\n",
      "Step: 50, norm=8.580, loss=0.000, obj=8.580\n",
      "Step: 100, norm=5.743, loss=0.013, obj=5.756\n",
      "Step: 150, norm=4.380, loss=0.000, obj=4.380\n",
      "Step: 200, norm=3.581, loss=0.000, obj=3.581\n",
      "Step: 250, norm=3.116, loss=0.000, obj=3.116\n",
      "Step: 300, norm=2.789, loss=0.000, obj=2.789\n",
      "Step: 350, norm=2.601, loss=0.000, obj=2.601\n",
      "Step: 400, norm=2.458, loss=0.000, obj=2.458\n",
      "Step: 450, norm=2.356, loss=0.000, obj=2.356\n",
      "Step: 500, norm=2.277, loss=0.000, obj=2.277\n",
      "Step: 550, norm=2.215, loss=0.000, obj=2.215\n",
      "Step: 600, norm=2.167, loss=0.000, obj=2.167\n",
      "Step: 650, norm=2.123, loss=0.000, obj=2.123\n",
      "Step: 700, norm=2.082, loss=0.000, obj=2.082\n",
      "Step: 750, norm=2.070, loss=0.000, obj=2.070\n",
      "Step: 800, norm=2.048, loss=0.000, obj=2.048\n",
      "Step: 850, norm=2.022, loss=0.000, obj=2.022\n",
      "Step: 900, norm=1.998, loss=0.000, obj=1.998\n",
      "Step: 950, norm=1.991, loss=0.000, obj=1.991\n",
      "Step: 0, norm=13.357, loss=0.000, obj=13.357\n",
      "Step: 50, norm=8.494, loss=0.000, obj=8.494\n",
      "Step: 100, norm=5.864, loss=0.000, obj=5.864\n",
      "Step: 150, norm=4.461, loss=0.000, obj=4.461\n",
      "Step: 200, norm=3.694, loss=0.000, obj=3.694\n",
      "Step: 250, norm=3.256, loss=0.000, obj=3.256\n",
      "Step: 300, norm=2.945, loss=0.000, obj=2.945\n",
      "Step: 350, norm=2.738, loss=0.000, obj=2.738\n",
      "Step: 400, norm=2.602, loss=0.000, obj=2.602\n",
      "Step: 450, norm=2.489, loss=0.000, obj=2.489\n",
      "Step: 500, norm=2.407, loss=0.000, obj=2.407\n",
      "Step: 550, norm=2.351, loss=0.000, obj=2.351\n",
      "Step: 600, norm=2.307, loss=0.000, obj=2.307\n",
      "Step: 650, norm=2.260, loss=0.000, obj=2.260\n",
      "Step: 700, norm=2.237, loss=0.000, obj=2.237\n",
      "Step: 750, norm=2.211, loss=0.000, obj=2.211\n",
      "Step: 800, norm=2.182, loss=0.000, obj=2.182\n",
      "Step: 850, norm=2.166, loss=0.000, obj=2.166\n",
      "Step: 900, norm=2.155, loss=0.000, obj=2.155\n",
      "Step: 950, norm=2.141, loss=0.000, obj=2.141\n",
      "Step: 0, norm=13.655, loss=0.000, obj=13.655\n",
      "Step: 50, norm=7.895, loss=0.000, obj=7.895\n",
      "Step: 100, norm=5.112, loss=0.000, obj=5.112\n",
      "Step: 150, norm=3.786, loss=0.000, obj=3.786\n",
      "Step: 200, norm=3.125, loss=0.000, obj=3.125\n",
      "Step: 250, norm=2.704, loss=0.000, obj=2.704\n",
      "Step: 300, norm=2.426, loss=0.000, obj=2.426\n",
      "Step: 350, norm=2.241, loss=0.000, obj=2.241\n",
      "Step: 400, norm=2.113, loss=0.000, obj=2.113\n",
      "Step: 450, norm=2.017, loss=0.000, obj=2.017\n",
      "Step: 500, norm=1.928, loss=0.004, obj=1.932\n",
      "Step: 550, norm=1.882, loss=0.000, obj=1.882\n",
      "Step: 600, norm=1.842, loss=0.000, obj=1.842\n",
      "Step: 650, norm=1.807, loss=0.000, obj=1.807\n",
      "Step: 700, norm=1.779, loss=0.000, obj=1.779\n",
      "Step: 750, norm=1.749, loss=0.000, obj=1.749\n",
      "Step: 800, norm=1.728, loss=0.000, obj=1.728\n",
      "Step: 850, norm=1.710, loss=0.000, obj=1.710\n",
      "Step: 900, norm=1.695, loss=0.000, obj=1.695\n",
      "Step: 950, norm=1.681, loss=0.000, obj=1.681\n",
      "Step: 0, norm=13.349, loss=0.000, obj=13.349\n",
      "Step: 50, norm=8.671, loss=0.000, obj=8.671\n",
      "Step: 100, norm=6.148, loss=0.000, obj=6.148\n",
      "Step: 150, norm=4.741, loss=0.000, obj=4.741\n",
      "Step: 200, norm=3.984, loss=0.000, obj=3.984\n",
      "Step: 250, norm=3.512, loss=0.000, obj=3.512\n",
      "Step: 300, norm=3.198, loss=0.000, obj=3.198\n",
      "Step: 350, norm=2.969, loss=0.000, obj=2.969\n",
      "Step: 400, norm=2.801, loss=0.000, obj=2.801\n",
      "Step: 450, norm=2.692, loss=0.000, obj=2.692\n",
      "Step: 500, norm=2.601, loss=0.000, obj=2.601\n",
      "Step: 550, norm=2.517, loss=0.001, obj=2.518\n",
      "Step: 600, norm=2.463, loss=0.000, obj=2.463\n",
      "Step: 650, norm=2.421, loss=0.000, obj=2.421\n",
      "Step: 700, norm=2.382, loss=0.000, obj=2.382\n",
      "Step: 750, norm=2.345, loss=0.000, obj=2.345\n",
      "Step: 800, norm=2.310, loss=0.000, obj=2.310\n",
      "Step: 850, norm=2.285, loss=0.000, obj=2.285\n",
      "Step: 900, norm=2.258, loss=0.000, obj=2.258\n",
      "Step: 950, norm=2.237, loss=0.000, obj=2.237\n",
      "Step: 0, norm=13.430, loss=0.000, obj=13.430\n",
      "Step: 50, norm=8.307, loss=0.000, obj=8.307\n",
      "Step: 100, norm=5.422, loss=0.000, obj=5.422\n",
      "Step: 150, norm=3.948, loss=0.000, obj=3.948\n",
      "Step: 200, norm=3.112, loss=0.000, obj=3.112\n",
      "Step: 250, norm=2.619, loss=0.000, obj=2.619\n",
      "Step: 300, norm=2.311, loss=0.000, obj=2.311\n",
      "Step: 350, norm=2.095, loss=0.000, obj=2.095\n",
      "Step: 400, norm=1.960, loss=0.000, obj=1.960\n",
      "Step: 450, norm=1.850, loss=0.000, obj=1.850\n",
      "Step: 500, norm=1.768, loss=0.000, obj=1.768\n",
      "Step: 550, norm=1.709, loss=0.000, obj=1.709\n",
      "Step: 600, norm=1.663, loss=0.000, obj=1.663\n",
      "Step: 650, norm=1.613, loss=0.000, obj=1.613\n",
      "Step: 700, norm=1.588, loss=0.000, obj=1.588\n",
      "Step: 750, norm=1.561, loss=0.000, obj=1.561\n",
      "Step: 800, norm=1.537, loss=0.000, obj=1.537\n",
      "Step: 850, norm=1.521, loss=0.000, obj=1.521\n",
      "Step: 900, norm=1.508, loss=0.000, obj=1.508\n",
      "Step: 950, norm=1.495, loss=0.000, obj=1.495\n",
      "Step: 0, norm=13.653, loss=0.000, obj=13.653\n",
      "Step: 50, norm=8.272, loss=0.000, obj=8.272\n",
      "Step: 100, norm=5.488, loss=0.000, obj=5.488\n",
      "Step: 150, norm=4.103, loss=0.000, obj=4.103\n",
      "Step: 200, norm=3.399, loss=0.000, obj=3.399\n",
      "Step: 250, norm=2.953, loss=0.000, obj=2.953\n",
      "Step: 300, norm=2.691, loss=0.000, obj=2.691\n",
      "Step: 350, norm=2.491, loss=0.000, obj=2.491\n",
      "Step: 400, norm=2.358, loss=0.000, obj=2.358\n",
      "Step: 450, norm=2.255, loss=0.000, obj=2.255\n",
      "Step: 500, norm=2.176, loss=0.000, obj=2.176\n",
      "Step: 550, norm=2.111, loss=0.000, obj=2.111\n",
      "Step: 600, norm=2.060, loss=0.000, obj=2.060\n",
      "Step: 650, norm=2.030, loss=0.000, obj=2.030\n",
      "Step: 700, norm=1.999, loss=0.000, obj=1.999\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-871cdbeeea61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         x_adv[i], norm[i] = opt.optimize(x, y, \n\u001b[1;32m     12\u001b[0m                                          \u001b[0;34m'./tmp/mnist_cnn_smxe.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                          n_step=1000, prog=True)\n\u001b[0m",
      "\u001b[0;32m~/princeton_thesis/lib/OptCarlini.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, x, y, weights_path, n_step, prog, mask)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# Keep track of \"best\" solution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0mfeed_handles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m       \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_dict_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msubfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfeed_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_feed_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mflatten_dict_items\u001b[0;34m(dictionary)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0mflat_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_dictionary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mis_sequence\u001b[0;34m(seq)\u001b[0m\n\u001b[1;32m    127\u001b[0m     _warn_once(\"Sets are not currently considered sequences, but this may \"\n\u001b[1;32m    128\u001b[0m                \"change in the future, so consider avoiding using them.\")\n\u001b[0;32m--> 129\u001b[0;31m   return (isinstance(seq, _collections.Sequence)\n\u001b[0m\u001b[1;32m    130\u001b[0m           and not isinstance(seq, _six.string_types))\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;31m# Inline the cache checking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = OptCarlini(model, target=False, c=1, lr=0.01, init_scl=0.1,\n",
    "                 use_bound=False, loss_op=0, k=0, var_change=True,\n",
    "                 use_mask=False)\n",
    "\n",
    "x_adv = np.zeros_like(x_test)\n",
    "norm = np.zeros(len(x_test))\n",
    "\n",
    "for i, (x, y) in enumerate(zip(x_test, y_test_cat)):\n",
    "    y_pred = predict(model, x)\n",
    "    if y_pred is not np.argmax(y):\n",
    "        x_adv[i], norm[i] = opt.optimize(x, y, \n",
    "                                         './tmp/mnist_cnn_smxe.h5', \n",
    "                                         n_step=1000, prog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, norm=13.448, loss=0.000, obj=13.448\n",
      "Step: 50, norm=8.389, loss=0.000, obj=8.389\n",
      "Step: 100, norm=5.837, loss=0.000, obj=5.837\n",
      "Step: 150, norm=4.483, loss=0.003, obj=4.486\n",
      "Step: 200, norm=3.761, loss=0.000, obj=3.761\n",
      "Step: 250, norm=3.256, loss=0.000, obj=3.256\n",
      "Step: 300, norm=2.922, loss=0.000, obj=2.922\n",
      "Step: 350, norm=2.702, loss=0.000, obj=2.702\n",
      "Step: 400, norm=2.547, loss=0.000, obj=2.547\n",
      "Step: 450, norm=2.442, loss=0.000, obj=2.442\n",
      "Step: 500, norm=2.349, loss=0.000, obj=2.349\n",
      "Step: 550, norm=2.266, loss=0.027, obj=2.292\n",
      "Step: 600, norm=2.220, loss=0.000, obj=2.220\n",
      "Step: 650, norm=2.178, loss=0.000, obj=2.178\n",
      "Step: 700, norm=2.142, loss=0.000, obj=2.142\n",
      "Step: 750, norm=2.109, loss=0.000, obj=2.109\n",
      "Step: 800, norm=2.085, loss=0.000, obj=2.085\n",
      "Step: 850, norm=2.074, loss=0.000, obj=2.074\n",
      "Step: 900, norm=2.058, loss=0.000, obj=2.058\n",
      "Step: 950, norm=2.039, loss=0.000, obj=2.039\n",
      "Step: 0, norm=13.334, loss=0.014, obj=13.348\n",
      "Step: 50, norm=8.460, loss=0.000, obj=8.460\n",
      "Step: 100, norm=5.854, loss=0.000, obj=5.854\n",
      "Step: 150, norm=4.511, loss=0.000, obj=4.511\n",
      "Step: 200, norm=3.753, loss=0.000, obj=3.753\n",
      "Step: 250, norm=3.270, loss=0.000, obj=3.270\n",
      "Step: 300, norm=2.989, loss=0.000, obj=2.989\n",
      "Step: 350, norm=2.789, loss=0.000, obj=2.789\n",
      "Step: 400, norm=2.645, loss=0.000, obj=2.645\n",
      "Step: 450, norm=2.523, loss=0.000, obj=2.523\n",
      "Step: 500, norm=2.431, loss=0.000, obj=2.431\n",
      "Step: 550, norm=2.377, loss=0.000, obj=2.377\n",
      "Step: 600, norm=2.317, loss=0.000, obj=2.317\n",
      "Step: 650, norm=2.275, loss=0.000, obj=2.275\n",
      "Step: 700, norm=2.243, loss=0.000, obj=2.243\n",
      "Step: 750, norm=2.198, loss=0.035, obj=2.234\n",
      "Step: 800, norm=2.186, loss=0.000, obj=2.186\n",
      "Step: 850, norm=2.167, loss=0.000, obj=2.167\n",
      "Step: 900, norm=2.146, loss=0.000, obj=2.146\n",
      "Step: 950, norm=2.120, loss=0.031, obj=2.152\n",
      "Step: 0, norm=13.618, loss=0.000, obj=13.618\n",
      "Step: 50, norm=7.874, loss=0.000, obj=7.874\n",
      "Step: 100, norm=5.087, loss=0.000, obj=5.087\n",
      "Step: 150, norm=3.764, loss=0.000, obj=3.764\n",
      "Step: 200, norm=3.080, loss=0.000, obj=3.080\n",
      "Step: 250, norm=2.671, loss=0.000, obj=2.671\n",
      "Step: 300, norm=2.403, loss=0.000, obj=2.403\n",
      "Step: 350, norm=2.214, loss=0.000, obj=2.214\n",
      "Step: 400, norm=2.091, loss=0.000, obj=2.091\n",
      "Step: 450, norm=1.999, loss=0.000, obj=1.999\n",
      "Step: 500, norm=1.909, loss=0.019, obj=1.928\n",
      "Step: 550, norm=1.861, loss=0.000, obj=1.861\n",
      "Step: 600, norm=1.824, loss=0.000, obj=1.824\n",
      "Step: 650, norm=1.785, loss=0.000, obj=1.785\n",
      "Step: 700, norm=1.759, loss=0.000, obj=1.759\n",
      "Step: 750, norm=1.731, loss=0.000, obj=1.731\n",
      "Step: 800, norm=1.712, loss=0.000, obj=1.712\n",
      "Step: 850, norm=1.691, loss=0.000, obj=1.691\n",
      "Step: 900, norm=1.674, loss=0.000, obj=1.674\n",
      "Step: 950, norm=1.660, loss=0.000, obj=1.660\n",
      "Step: 0, norm=13.394, loss=0.000, obj=13.394\n",
      "Step: 50, norm=8.653, loss=0.000, obj=8.653\n",
      "Step: 100, norm=6.119, loss=0.000, obj=6.119\n",
      "Step: 150, norm=4.686, loss=0.000, obj=4.686\n",
      "Step: 200, norm=3.861, loss=0.000, obj=3.861\n",
      "Step: 250, norm=3.300, loss=0.000, obj=3.300\n",
      "Step: 300, norm=2.919, loss=0.000, obj=2.919\n",
      "Step: 350, norm=2.670, loss=0.000, obj=2.670\n",
      "Step: 400, norm=2.481, loss=0.000, obj=2.481\n",
      "Step: 450, norm=2.365, loss=0.000, obj=2.365\n",
      "Step: 500, norm=2.276, loss=0.000, obj=2.276\n",
      "Step: 550, norm=2.202, loss=0.000, obj=2.202\n",
      "Step: 600, norm=2.145, loss=0.000, obj=2.145\n",
      "Step: 650, norm=2.096, loss=0.000, obj=2.096\n",
      "Step: 700, norm=2.052, loss=0.027, obj=2.079\n",
      "Step: 750, norm=2.033, loss=0.000, obj=2.033\n",
      "Step: 800, norm=2.010, loss=0.000, obj=2.010\n",
      "Step: 850, norm=1.981, loss=0.000, obj=1.981\n",
      "Step: 900, norm=1.967, loss=0.000, obj=1.967\n",
      "Step: 950, norm=1.952, loss=0.000, obj=1.952\n",
      "Step: 0, norm=13.404, loss=0.000, obj=13.404\n",
      "Step: 50, norm=8.207, loss=0.000, obj=8.207\n",
      "Step: 100, norm=5.318, loss=0.000, obj=5.318\n",
      "Step: 150, norm=3.852, loss=0.000, obj=3.852\n",
      "Step: 200, norm=3.073, loss=0.000, obj=3.073\n",
      "Step: 250, norm=2.578, loss=0.000, obj=2.578\n",
      "Step: 300, norm=2.269, loss=0.000, obj=2.269\n",
      "Step: 350, norm=2.069, loss=0.000, obj=2.069\n",
      "Step: 400, norm=1.922, loss=0.000, obj=1.922\n",
      "Step: 450, norm=1.818, loss=0.000, obj=1.818\n",
      "Step: 500, norm=1.737, loss=0.000, obj=1.737\n",
      "Step: 550, norm=1.684, loss=0.000, obj=1.684\n",
      "Step: 600, norm=1.638, loss=0.000, obj=1.638\n",
      "Step: 650, norm=1.597, loss=0.000, obj=1.597\n",
      "Step: 700, norm=1.569, loss=0.000, obj=1.569\n",
      "Step: 750, norm=1.541, loss=0.000, obj=1.541\n",
      "Step: 800, norm=1.519, loss=0.000, obj=1.519\n",
      "Step: 850, norm=1.499, loss=0.000, obj=1.499\n",
      "Step: 900, norm=1.481, loss=0.000, obj=1.481\n",
      "Step: 950, norm=1.466, loss=0.000, obj=1.466\n",
      "Step: 0, norm=13.638, loss=0.000, obj=13.638\n",
      "Step: 50, norm=8.358, loss=0.000, obj=8.358\n",
      "Step: 100, norm=5.565, loss=0.000, obj=5.565\n",
      "Step: 150, norm=4.158, loss=0.000, obj=4.158\n",
      "Step: 200, norm=3.476, loss=0.000, obj=3.476\n",
      "Step: 250, norm=3.041, loss=0.000, obj=3.041\n",
      "Step: 300, norm=2.784, loss=0.000, obj=2.784\n",
      "Step: 350, norm=2.601, loss=0.000, obj=2.601\n",
      "Step: 400, norm=2.465, loss=0.000, obj=2.465\n",
      "Step: 450, norm=2.361, loss=0.044, obj=2.404\n",
      "Step: 500, norm=2.307, loss=0.000, obj=2.307\n",
      "Step: 550, norm=2.250, loss=0.000, obj=2.250\n",
      "Step: 600, norm=2.200, loss=0.000, obj=2.200\n",
      "Step: 650, norm=2.153, loss=0.026, obj=2.179\n",
      "Step: 700, norm=2.138, loss=0.000, obj=2.138\n",
      "Step: 750, norm=2.099, loss=0.001, obj=2.101\n",
      "Step: 800, norm=2.087, loss=0.000, obj=2.087\n",
      "Step: 850, norm=2.058, loss=0.004, obj=2.062\n",
      "Step: 900, norm=2.053, loss=0.000, obj=2.053\n",
      "Step: 950, norm=2.028, loss=0.003, obj=2.031\n",
      "Step: 0, norm=13.342, loss=0.000, obj=13.342\n",
      "Step: 50, norm=8.312, loss=0.000, obj=8.312\n",
      "Step: 100, norm=5.291, loss=0.000, obj=5.291\n",
      "Step: 150, norm=3.721, loss=0.000, obj=3.721\n",
      "Step: 200, norm=2.800, loss=0.000, obj=2.800\n",
      "Step: 250, norm=2.264, loss=0.000, obj=2.264\n",
      "Step: 300, norm=1.933, loss=0.000, obj=1.933\n",
      "Step: 350, norm=1.691, loss=0.000, obj=1.691\n",
      "Step: 400, norm=1.537, loss=0.000, obj=1.537\n",
      "Step: 450, norm=1.430, loss=0.000, obj=1.430\n",
      "Step: 500, norm=1.344, loss=0.000, obj=1.344\n",
      "Step: 550, norm=1.285, loss=0.000, obj=1.285\n",
      "Step: 600, norm=1.234, loss=0.000, obj=1.234\n",
      "Step: 650, norm=1.198, loss=0.000, obj=1.198\n",
      "Step: 700, norm=1.161, loss=0.000, obj=1.161\n",
      "Step: 750, norm=1.142, loss=0.000, obj=1.142\n",
      "Step: 800, norm=1.117, loss=0.000, obj=1.117\n",
      "Step: 850, norm=1.103, loss=0.000, obj=1.103\n",
      "Step: 900, norm=1.087, loss=0.000, obj=1.087\n",
      "Step: 950, norm=1.074, loss=0.000, obj=1.074\n",
      "Step: 0, norm=13.440, loss=0.000, obj=13.440\n",
      "Step: 50, norm=8.191, loss=0.000, obj=8.191\n",
      "Step: 100, norm=5.390, loss=0.087, obj=5.478\n",
      "Step: 150, norm=4.028, loss=0.000, obj=4.028\n",
      "Step: 200, norm=3.187, loss=0.068, obj=3.255\n",
      "Step: 250, norm=2.706, loss=0.021, obj=2.727\n",
      "Step: 300, norm=2.415, loss=0.000, obj=2.415\n",
      "Step: 350, norm=2.204, loss=0.000, obj=2.204\n",
      "Step: 400, norm=2.058, loss=0.000, obj=2.058\n",
      "Step: 450, norm=1.935, loss=0.000, obj=1.935\n",
      "Step: 500, norm=1.865, loss=0.000, obj=1.865\n",
      "Step: 550, norm=1.807, loss=0.000, obj=1.807\n",
      "Step: 600, norm=1.755, loss=0.000, obj=1.755\n",
      "Step: 650, norm=1.716, loss=0.000, obj=1.716\n",
      "Step: 700, norm=1.680, loss=0.000, obj=1.680\n",
      "Step: 750, norm=1.652, loss=0.000, obj=1.652\n",
      "Step: 800, norm=1.631, loss=0.000, obj=1.631\n",
      "Step: 850, norm=1.614, loss=0.000, obj=1.614\n",
      "Step: 900, norm=1.596, loss=0.000, obj=1.596\n",
      "Step: 950, norm=1.578, loss=0.000, obj=1.578\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-871cdbeeea61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         x_adv[i], norm[i] = opt.optimize(x, y, \n\u001b[1;32m     12\u001b[0m                                          \u001b[0;34m'./tmp/mnist_cnn_smxe.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                          n_step=1000, prog=True)\n\u001b[0m",
      "\u001b[0;32m~/princeton_thesis/lib/OptCarlini.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, x, y, weights_path, n_step, prog, mask)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;31m# Initialize variables and load weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1291\u001b[0m                 run_metadata):\n\u001b[1;32m   1292\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         graph_def, self._current_version = self._graph._as_graph_def(\n\u001b[1;32m   1348\u001b[0m             \u001b[0mfrom_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m             add_shapes=self._add_shapes)\n\u001b[0m\u001b[1;32m   1350\u001b[0m         \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tsa3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_def\u001b[0;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[1;32m   2724\u001b[0m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfrom_version\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mop_id\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mfrom_version\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m           \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0madd_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m\"_output_shapes\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = OptCarlini(model, target=False, c=1, lr=0.01, init_scl=0.1,\n",
    "                 use_bound=False, loss_op=0, k=0, var_change=True,\n",
    "                 use_mask=False)\n",
    "\n",
    "x_adv = np.zeros_like(x_test)\n",
    "norm = np.zeros(len(x_test))\n",
    "\n",
    "for i, (x, y) in enumerate(zip(x_test, y_test_cat)):\n",
    "    y_pred = predict(model, x)\n",
    "    if y_pred is not np.argmax(y):\n",
    "        x_adv[i], norm[i] = opt.optimize(x, y, \n",
    "                                         './tmp/mnist_cnn_smxe.h5', \n",
    "                                         n_step=1000, prog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAADO5JREFUeJzt3V2IXfW5x/Hf76QpiOlFYjUMNpqeogerSKKjCMYS9VhyYiEWg9SLkkLJ9CJKCyVU7EVzWaQv1JvAlIbGkmMrpNUoYmNjMQ1qcSJqEmNiElIzMW9lhCaCtNGnF7Nsp3H2f+/st7XH5/uBYfZez3p52Mxv1lp77bX/jggByOe/6m4AQD0IP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpD7Vz43Z5uOEQI9FhFuZr6M9v+1ltvfZPmD7gU7WBaC/3O5n+23PkrRf0h2SxiW9LOneiHijsAx7fqDH+rHnv1HSgYg4FBF/l/RrSSs6WB+APuok/JdKOjLl+Xg17T/YHrE9Znusg20B6LKev+EXEaOSRiUO+4FB0sme/6ikBVOef66aBmAG6CT8L0u6wvbnbX9a0tckbelOWwB6re3D/og4a/s+Sb+XNEvShojY07XOAPRU25f62toY5/xAz/XlQz4AZi7CDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmp7iG5Jsn1Y0mlJH0g6GxHD3WgKQO91FP7KrRHx1y6sB0AfcdgPJNVp+EPSVts7bY90oyEA/dHpYf+SiDhq+xJJz9p+MyK2T52h+qfAPwZgwDgiurMie52kMxHxo8I83dkYgIYiwq3M1/Zhv+0LbX/mo8eSvixpd7vrA9BfnRz2z5f0O9sfref/I+KZrnQFoOe6dtjf0sY47Ad6rueH/QBmNsIPJEX4gaQIP5AU4QeSIvxAUt24qy+FlStXNqytXr26uOw777xTrL///vvF+qZNm4r148ePN6wdOHCguCzyYs8PJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0lxS2+LDh061LC2cOHC/jUyjdOnTzes7dmzp4+dDJbx8fGGtYceeqi47NjYWLfb6Rtu6QVQRPiBpAg/kBThB5Ii/EBShB9IivADSXE/f4tK9+xfe+21xWX37t1brF911VXF+nXXXVesL126tGHtpptuKi575MiRYn3BggXFeifOnj1brJ86dapYHxoaanvbb7/9drE+k6/zt4o9P5AU4QeSIvxAUoQfSIrwA0kRfiApwg8k1fR+ftsbJH1F0smIuKaaNk/SbyQtlHRY0j0R8W7Tjc3g+/kH2dy5cxvWFi1aVFx2586dxfoNN9zQVk+taDZewf79+4v1Zp+fmDdvXsPamjVrisuuX7++WB9k3byf/5eSlp0z7QFJ2yLiCknbqucAZpCm4Y+I7ZImzpm8QtLG6vFGSXd1uS8APdbuOf/8iDhWPT4uaX6X+gHQJx1/tj8ionQub3tE0kin2wHQXe3u+U/YHpKk6vfJRjNGxGhEDEfEcJvbAtAD7YZ/i6RV1eNVkp7oTjsA+qVp+G0/KulFSf9je9z2NyX9UNIdtt+S9L/VcwAzCN/bj4F19913F+uPPfZYsb579+6GtVtvvbW47MTEuRe4Zg6+tx9AEeEHkiL8QFKEH0iK8ANJEX4gKS71oTaXXHJJsb5r166Oll+5cmXD2ubNm4vLzmRc6gNQRPiBpAg/kBThB5Ii/EBShB9IivADSTFEN2rT7OuzL7744mL93XfL3xa/b9++8+4pE/b8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU9/Ojp26++eaGteeee6647OzZs4v1pUuXFuvbt28v1j+puJ8fQBHhB5Ii/EBShB9IivADSRF+ICnCDyTV9H5+2xskfUXSyYi4ppq2TtJqSaeq2R6MiKd71SRmruXLlzesNbuOv23btmL9xRdfbKsnTGplz/9LScummf7TiFhU/RB8YIZpGv6I2C5pog+9AOijTs7577P9uu0Ntud2rSMAfdFu+NdL+oKkRZKOSfpxoxltj9gesz3W5rYA9EBb4Y+IExHxQUR8KOnnkm4szDsaEcMRMdxukwC6r63w2x6a8vSrknZ3px0A/dLKpb5HJS2V9Fnb45J+IGmp7UWSQtJhSd/qYY8AeoD7+dGRCy64oFjfsWNHw9rVV19dXPa2224r1l944YViPSvu5wdQRPiBpAg/kBThB5Ii/EBShB9IiiG60ZG1a9cW64sXL25Ye+aZZ4rLcimvt9jzA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBS3NKLojvvvLNYf/zxx4v19957r2Ft2bLpvhT631566aViHdPjll4ARYQfSIrwA0kRfiApwg8kRfiBpAg/kBT38yd30UUXFesPP/xwsT5r1qxi/emnGw/gzHX8erHnB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkmt7Pb3uBpEckzZcUkkYj4me250n6jaSFkg5Luici3m2yLu7n77Nm1+GbXWu//vrri/WDBw8W66V79psti/Z0837+s5K+GxFflHSTpDW2vyjpAUnbIuIKSduq5wBmiKbhj4hjEfFK9fi0pL2SLpW0QtLGaraNku7qVZMAuu+8zvltL5S0WNKfJc2PiGNV6bgmTwsAzBAtf7bf9hxJmyV9JyL+Zv/7tCIiotH5vO0RSSOdNgqgu1ra89uercngb4qI31aTT9gequpDkk5Ot2xEjEbEcEQMd6NhAN3RNPye3MX/QtLeiPjJlNIWSauqx6skPdH99gD0SiuX+pZI+pOkXZI+rCY/qMnz/sckXSbpL5q81DfRZF1c6uuzK6+8slh/8803O1r/ihUrivUnn3yyo/Xj/LV6qa/pOX9E7JDUaGW3n09TAAYHn/ADkiL8QFKEH0iK8ANJEX4gKcIPJMVXd38CXH755Q1rW7du7Wjda9euLdafeuqpjtaP+rDnB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkuM7/CTAy0vhb0i677LKO1v38888X682+DwKDiz0/kBThB5Ii/EBShB9IivADSRF+ICnCDyTFdf4ZYMmSJcX6/fff36dO8EnCnh9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmp6nd/2AkmPSJovKSSNRsTPbK+TtFrSqWrWByPi6V41mtktt9xSrM+ZM6ftdR88eLBYP3PmTNvrxmBr5UM+ZyV9NyJesf0ZSTttP1vVfhoRP+pdewB6pWn4I+KYpGPV49O290q6tNeNAeit8zrnt71Q0mJJf64m3Wf7ddsbbM9tsMyI7THbYx11CqCrWg6/7TmSNkv6TkT8TdJ6SV+QtEiTRwY/nm65iBiNiOGIGO5CvwC6pKXw256tyeBviojfSlJEnIiIDyLiQ0k/l3Rj79oE0G1Nw2/bkn4haW9E/GTK9KEps31V0u7utwegV1p5t/9mSV+XtMv2q9W0ByXda3uRJi//HZb0rZ50iI689tprxfrtt99erE9MTHSzHQyQVt7t3yHJ05S4pg/MYHzCD0iK8ANJEX4gKcIPJEX4gaQIP5CU+znEsm3GcwZ6LCKmuzT/Mez5gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiCpfg/R/VdJf5ny/LPVtEE0qL0Nal8SvbWrm71d3uqMff2Qz8c2bo8N6nf7DWpvg9qXRG/tqqs3DvuBpAg/kFTd4R+tefslg9rboPYl0Vu7aumt1nN+APWpe88PoCa1hN/2Mtv7bB+w/UAdPTRi+7DtXbZfrXuIsWoYtJO2d0+ZNs/2s7bfqn5PO0xaTb2ts320eu1etb28pt4W2P6j7Tds77H97Wp6ra9doa9aXre+H/bbniVpv6Q7JI1LelnSvRHxRl8bacD2YUnDEVH7NWHbX5J0RtIjEXFNNe0hSRMR8cPqH+fciPjegPS2TtKZukdurgaUGZo6srSkuyR9QzW+doW+7lENr1sde/4bJR2IiEMR8XdJv5a0ooY+Bl5EbJd07qgZKyRtrB5v1OQfT9816G0gRMSxiHilenxa0kcjS9f62hX6qkUd4b9U0pEpz8c1WEN+h6SttnfaHqm7mWnMr4ZNl6TjkubX2cw0mo7c3E/njCw9MK9dOyNedxtv+H3ckoi4TtL/SVpTHd4OpJg8ZxukyzUtjdzcL9OMLP0vdb527Y543W11hP+opAVTnn+umjYQIuJo9fukpN9p8EYfPvHRIKnV75M19/MvgzRy83QjS2sAXrtBGvG6jvC/LOkK25+3/WlJX5O0pYY+Psb2hdUbMbJ9oaQva/BGH94iaVX1eJWkJ2rs5T8MysjNjUaWVs2v3cCNeB0Rff+RtFyT7/gflPT9Onpo0Nd/S3qt+tlTd2+SHtXkYeA/NPneyDclXSRpm6S3JP1B0rwB6u1XknZJel2TQRuqqbclmjykf13Sq9XP8rpfu0JftbxufMIPSIo3/ICkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJPVP82g/p9/JjhUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "plt.imshow(x_adv[i].reshape(28, 28), cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "plt.show()\n",
    "predict(model, x_adv[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.7619686784297228\n"
     ]
    }
   ],
   "source": [
    "adv_path = './tmp/adv/mnist_cnn_smxe_ut'\n",
    "\n",
    "x_adv = pickle.load(open(adv_path + '.p', 'rb'))\n",
    "norm = pickle.load(open(adv_path + '_norm.p', 'rb'))\n",
    "\n",
    "print(eval_adv(model, x_adv, y_test_cat[:1000], target=False))\n",
    "print(np.mean(norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n",
      "1.7483367365896703\n"
     ]
    }
   ],
   "source": [
    "adv_path = './tmp/adv/mnist_cnn_hinge_ut'\n",
    "\n",
    "x_adv = pickle.load(open(adv_path + '.p', 'rb'))\n",
    "norm = pickle.load(open(adv_path + '_norm.p', 'rb'))\n",
    "\n",
    "print(eval_adv(model, x_adv, y_test_cat[:1000], target=False))\n",
    "print(np.mean(norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.9846761872768401\n"
     ]
    }
   ],
   "source": [
    "adv_path = './tmp/adv/mnist_cnn_hinge_10_ut'\n",
    "\n",
    "x_adv = pickle.load(open(adv_path + '.p', 'rb'))\n",
    "norm = pickle.load(open(adv_path + '_norm.p', 'rb'))\n",
    "\n",
    "print(eval_adv(model, x_adv, y_test_cat[:1000], target=False))\n",
    "print(np.mean(norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2.0220260658711195\n"
     ]
    }
   ],
   "source": [
    "adv_path = './tmp/adv/mnist_cnn_smxe_ut_w'\n",
    "\n",
    "x_adv = pickle.load(open(adv_path + '.p', 'rb'))\n",
    "norm = pickle.load(open(adv_path + '_norm.p', 'rb'))\n",
    "\n",
    "print(eval_adv(model, x_adv, y_test_cat[:1000], target=False))\n",
    "print(np.mean(norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.257\n",
      "0.6817249667933211\n"
     ]
    }
   ],
   "source": [
    "adv_path = './tmp/adv/mnist_cnn_margin_C1_L1'\n",
    "\n",
    "x_adv = pickle.load(open(adv_path + '.p', 'rb'))\n",
    "norm = pickle.load(open(adv_path + '_norm.p', 'rb'))\n",
    "\n",
    "print(eval_adv(model, x_adv, y_test_cat[:1000], target=False))\n",
    "print(np.mean(norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 132us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46184693212509154, 0.96]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.8874,\n",
       "  0.9267,\n",
       "  0.9428,\n",
       "  0.8998,\n",
       "  0.958,\n",
       "  0.947,\n",
       "  0.9274,\n",
       "  0.9514,\n",
       "  0.9574,\n",
       "  0.96,\n",
       "  0.9482,\n",
       "  0.9489],\n",
       " 'loss': [59.199047,\n",
       "  38.387955,\n",
       "  30.049332,\n",
       "  45.49747,\n",
       "  22.247637,\n",
       "  25.692705,\n",
       "  39.69093,\n",
       "  23.924044,\n",
       "  21.638086,\n",
       "  19.400446,\n",
       "  24.211601,\n",
       "  23.441643]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
